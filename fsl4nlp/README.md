[![](https://img.shields.io/badge/Awesome_Continual_Learning-yellow)](https://github.com/wutong8023/Awesome_Continual_Learning.git) [![](https://img.shields.io/badge/Awesome_Few_Shot_learning-green)](https://github.com/wutong8023/Awesome_Few_Shot_Learning.git) [![](https://img.shields.io/badge/Awesome_Information_Extraction-blue)](https://github.com/wutong8023/Awesome_Information_Extraction.git) [![](https://img.shields.io/badge/Awesome_Ideas-orange)](https://github.com/wutong8023/Awesome_Ideas.git)

# Few-shot Learning Literature in NLP 
This repository is maintained by [Tongtong Wu](http://wutong8023.site). Please don't hesitate to send me an email to collaborate or fix some entries (wutong8023 AT gmail.com). 
The automation script of this repo is powered by [Auto-Bibfile](https://github.com/wutong8023/Auto-Bibfile.git).

You can directly use our bibtex.bib in overleaf with this [link](https://www.overleaf.com/read/rgscdxhxbwhp).

This page categorizes the literature by the **Published Venue**, filtered by NLP area.

## Outline 
- [![](https://img.shields.io/badge/Hyperlink-green)](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/./README.md#hyperlink)
- [![](https://img.shields.io/badge/arXiv-7-green)](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/./README.md#arxiv)
## Hyperlink 
- [[Overview]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/README.md) -- [Homepage](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/README.md)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/./)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/./) -- [Summary](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/./)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/application)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/application) -- [Application](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/application)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/approach)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/approach) -- [Approach](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/approach)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/author)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/author) -- [Author](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/author)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/backbone_model)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/backbone_model) -- [Backbone Model](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/backbone_model)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/contribution)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/contribution) -- [Contribution](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/contribution)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/dataset)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/dataset) -- [Dataset](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/dataset)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/metrics)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/metrics) -- [Metrics](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/metrics)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/research_question)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/research_question) -- [Research Questions](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/research_question)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/setting)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/setting) -- [Setting](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/setting)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/supervision)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/supervision) -- [ Learning Paradigm](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/supervision)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/time)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/time) -- [Published Time](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/time)
- [[NLP]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4nlp/venue)  [[CV]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4cv/venue) -- [Published Venue](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/fsl4all/venue)

## arXiv

- [![](https://img.shields.io/badge/CoRR-2021-green)](https://arxiv.org/abs/2103.11955)<a href="https://scholar.google.com.hk/scholar?q=Improving+and+Simplifying+Pattern+Exploiting+Training"><img src="https://img.shields.io/badge/-green.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Improving and Simplifying Pattern Exploiting Training**](https://arxiv.org/abs/2103.11955) , <br> by *Derek Tam and
Rakesh R. Menon and
Mohit Bansal and
Shashank Srivastava and
Colin Raffel* [[bib]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/./bibtex.bib#L2762-L2777) <br>```EMNLP 2021, proposing ADAPET which promisingly improves the data efficiency of PET. ADAPET does not leverage unlabelled data for training, and introduces label-conditioned loss for the denser supervision.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```abs-2103-11955```
- [![](https://img.shields.io/badge/CoRR-2021-green)](https://arxiv.org/abs/2104.07972)<a href="https://scholar.google.com.hk/scholar?q=Language+Models+are+Few-Shot+Butlers"><img src="https://img.shields.io/badge/-green.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Language Models are Few-Shot Butlers**](https://arxiv.org/abs/2104.07972) , <br> by *Vincent Micheli and
Fran{\c{c}}ois Fleuret* [[bib]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/./bibtex.bib#L2781-L2792) <br>```EMNLP 2021, proposing to use RL and few-shot supervised learning for text generation.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```abs-2104-07972```
- [![](https://img.shields.io/badge/CoRR-2021-green)](https://arxiv.org/abs/2108.13487)<a href="https://scholar.google.com.hk/scholar?q=Want+To+Reduce+Labeling+Cost?+GPT-3+Can+Help"><img src="https://img.shields.io/badge/-green.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Want To Reduce Labeling Cost? GPT-3 Can Help**](https://arxiv.org/abs/2108.13487) , <br> by *Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu and Michael Zeng* [[bib]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/./bibtex.bib#L2795-L2805) <br>```EMNLP Findings 2021, adopting GPT-3 for label generation.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```wang2021want```
- [![](https://img.shields.io/badge/CoRR-2021-green)](https://arxiv.org/abs/2109.01951)<a href="https://scholar.google.com.hk/scholar?q=FewshotQA:+A+simple+framework+for+few-shot+learning+of+question+answering+tasks+using+pre-trained+text-to-text+models"><img src="https://img.shields.io/badge/-green.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**FewshotQA: A simple framework for few-shot learning of question answering tasks using pre-trained text-to-text models**](https://arxiv.org/abs/2109.01951) , <br> by *Rakesh Chada and Pradeep Natarajan* [[bib]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/./bibtex.bib#L2809-L2819) <br>```EMNLP 2021
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```chada2021fewshotqa```
- [![](https://img.shields.io/badge/CoRR-2021-green)](https://arxiv.org/abs/2109.03630)<a href="https://scholar.google.com.hk/scholar?q=Discrete+and+Soft+Prompting+for+Multilingual+Models"><img src="https://img.shields.io/badge/-green.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**Discrete and Soft Prompting for Multilingual Models**](https://arxiv.org/abs/2109.03630) , <br> by *Mengjie Zhao and Hinrich Sch√ºtze* [[bib]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/./bibtex.bib#L2823-L2833) <br>```EMNLP 2021
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```zhao2021discrete```
- [![](https://img.shields.io/badge/CoRR-2021-green)](https://arxiv.org/abs/2109.06270)<a href="https://scholar.google.com.hk/scholar?q=STraTA:+Self-Training+with+Task+Augmentation+for+Better+Few-shot+Learning"><img src="https://img.shields.io/badge/-green.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**STraTA: Self-Training with Task Augmentation for Better Few-shot Learning**](https://arxiv.org/abs/2109.06270) , <br> by *Tu Vu, Minh-Thang Luong, Quoc V. Le, Grady Simon and Mohit Iyyer* [[bib]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/./bibtex.bib#L2836-L2846) <br>```EMNLP 2021, pretrained language model-based self-training and data agumentation for few-shot learning.
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```vu2021strata```
- [![](https://img.shields.io/badge/CoRR-2021-green)](https://arxiv.org/abs/2109.04108)<a href="https://scholar.google.com.hk/scholar?q=MapRE:+An+Effective+Semantic+Mapping+Approach+for+Low-resource+Relation+Extraction"><img src="https://img.shields.io/badge/-green.svg?&logo=google-scholar&logoColor=white" height="18" align="bottom"></a> [**MapRE: An Effective Semantic Mapping Approach for Low-resource Relation Extraction**](https://arxiv.org/abs/2109.04108) , <br> by *Manqing Dong, Chunguang Pan and Zhipeng Luo* [[bib]](https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/./bibtex.bib#L2849-L2859) <br>```EMNLP 2021, proposing a label-aware method for low-resource relation extraction
```</details><details><summary><img src=https://github.com/wutong8023/Awesome_Few_Shot_Learning/blob/master/scripts/svg/copy_icon.png height="20" align="bottom"></summary><pre>```dong2021mapre```